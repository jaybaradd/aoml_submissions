{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-09T15:28:31.324289Z",
     "iopub.status.busy": "2025-02-09T15:28:31.323998Z",
     "iopub.status.idle": "2025-02-09T15:28:39.085946Z",
     "shell.execute_reply": "2025-02-09T15:28:39.084832Z",
     "shell.execute_reply.started": "2025-02-09T15:28:31.324254Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.experimental import enable_iterative_imputer  # Enable IterativeImputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T15:29:17.233144Z",
     "iopub.status.busy": "2025-02-09T15:29:17.232730Z",
     "iopub.status.idle": "2025-02-09T15:29:17.507442Z",
     "shell.execute_reply": "2025-02-09T15:29:17.506417Z",
     "shell.execute_reply.started": "2025-02-09T15:29:17.233086Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/kaggle/input/aoml-m-2-test-feb-2025/train.csv')\n",
    "data = pd.get_dummies(data, columns=['day'], drop_first=True, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T15:29:20.829724Z",
     "iopub.status.busy": "2025-02-09T15:29:20.829346Z",
     "iopub.status.idle": "2025-02-09T15:33:15.098283Z",
     "shell.execute_reply": "2025-02-09T15:33:15.096910Z",
     "shell.execute_reply.started": "2025-02-09T15:29:20.829690Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = data.drop(['output_electricity_generation'],axis=1)\n",
    "y = data[['output_electricity_generation']]\n",
    "\n",
    "train_imputer = IterativeImputer(\n",
    "    estimator=XGBRegressor(n_estimators=120, learning_rate=0.1, max_depth=10, random_state=42), \n",
    "    max_iter=12,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_imputed = train_imputer.fit_transform(X) \n",
    "X_imp_df = pd.DataFrame(X_imputed, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T15:34:50.928256Z",
     "iopub.status.busy": "2025-02-09T15:34:50.927884Z",
     "iopub.status.idle": "2025-02-09T15:34:50.940687Z",
     "shell.execute_reply": "2025-02-09T15:34:50.939653Z",
     "shell.execute_reply.started": "2025-02-09T15:34:50.928230Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50400, 36)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_imp_df.drop(['uid'],axis=1,inplace=True)\n",
    "X_imp_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T15:35:57.657179Z",
     "iopub.status.busy": "2025-02-09T15:35:57.656811Z",
     "iopub.status.idle": "2025-02-09T15:35:58.255237Z",
     "shell.execute_reply": "2025-02-09T15:35:58.254166Z",
     "shell.execute_reply.started": "2025-02-09T15:35:57.657151Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poly train shape (50400, 702)\n",
      "Poly test shape (21600, 702)\n"
     ]
    }
   ],
   "source": [
    "poly_feat_creator = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "poly_feat_train = poly_feat_creator.fit_transform(X_imp_df)\n",
    "poly_feat_test = poly_feat_creator.transform(test_df_imp)\n",
    "\n",
    "print(\"Poly train shape\", poly_feat_train.shape)\n",
    "print(\"Poly test shape\", poly_feat_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T15:38:01.579650Z",
     "iopub.status.busy": "2025-02-09T15:38:01.579291Z",
     "iopub.status.idle": "2025-02-09T15:38:02.095635Z",
     "shell.execute_reply": "2025-02-09T15:38:02.094495Z",
     "shell.execute_reply.started": "2025-02-09T15:38:01.579623Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "mmscaler = MinMaxScaler()\n",
    "yscaler = MinMaxScaler()\n",
    "\n",
    "X_scl = mmscaler.fit_transform(poly_feat_train)\n",
    "y_scl = yscaler.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scl, y_scl, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T15:38:34.282637Z",
     "iopub.status.busy": "2025-02-09T15:38:34.282305Z",
     "iopub.status.idle": "2025-02-09T15:44:07.442026Z",
     "shell.execute_reply": "2025-02-09T15:44:07.440952Z",
     "shell.execute_reply.started": "2025-02-09T15:38:34.282611Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-aa060268c009>:17: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf_model.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.054339087661661976\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Define parameters for Random Forest\n",
    "rf_params = {\n",
    "    'n_estimators': 100,    # Equivalent to num_round in XGBoost\n",
    "    'max_depth': 8,         # Similar to XGBoost's max_depth\n",
    "    'min_samples_split': 5, # Equivalent to controlling overfitting\n",
    "    'min_samples_leaf': 2,  # Controls leaf size, like regularization\n",
    "    'max_features': 0.7,    # Similar to colsample_bytree\n",
    "    'max_samples': 0.7,     # Similar to subsample\n",
    "    'n_jobs': -1,           # Use all processors\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "rf_model = RandomForestRegressor(**rf_params)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = rf_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(f'RMSE: {np.sqrt(mse)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T15:46:47.953506Z",
     "iopub.status.busy": "2025-02-09T15:46:47.952934Z",
     "iopub.status.idle": "2025-02-09T16:08:30.202576Z",
     "shell.execute_reply": "2025-02-09T16:08:30.201502Z",
     "shell.execute_reply.started": "2025-02-09T15:46:47.953465Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation RMSE Scores: [0.0033037  0.00300496 0.00266167 0.00267846 0.00286759]\n",
      "Mean RMSE: 0.0029\n",
      "Standard Deviation of RMSE: 0.0002\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "import numpy as np\n",
    "\n",
    "# Define RMSE as the evaluation metric\n",
    "rmse_scorer = make_scorer(mean_squared_error, squared=False)\n",
    "\n",
    "# Define Random Forest parameters\n",
    "rf_params = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 8,\n",
    "    'min_samples_split': 5,\n",
    "    'min_samples_leaf': 2,\n",
    "    'max_features': 0.7,\n",
    "    'max_samples': 0.7,\n",
    "    'n_jobs': -1,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "# Initialize the RandomForestRegressor\n",
    "rf_model = RandomForestRegressor(**rf_params)\n",
    "\n",
    "# Perform 5-Fold Cross-Validation\n",
    "cv_scores = cross_val_score(rf_model, X_train, y_train, cv=5, scoring=rmse_scorer)\n",
    "\n",
    "# Print results\n",
    "print(f\"Cross-Validation RMSE Scores: {cv_scores}\")\n",
    "print(f\"Mean RMSE: {np.mean(cv_scores):.4f}\")\n",
    "print(f\"Standard Deviation of RMSE: {np.std(cv_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T16:35:20.543440Z",
     "iopub.status.busy": "2025-02-09T16:35:20.543057Z",
     "iopub.status.idle": "2025-02-09T16:35:20.549327Z",
     "shell.execute_reply": "2025-02-09T16:35:20.548311Z",
     "shell.execute_reply.started": "2025-02-09T16:35:20.543412Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 100,\n",
       " 'max_depth': 8,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 0.7,\n",
       " 'max_samples': 0.7,\n",
       " 'n_jobs': -1,\n",
       " 'random_state': 42}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T16:36:07.895423Z",
     "iopub.status.busy": "2025-02-09T16:36:07.895043Z",
     "iopub.status.idle": "2025-02-09T17:03:18.969289Z",
     "shell.execute_reply": "2025-02-09T17:03:18.968213Z",
     "shell.execute_reply.started": "2025-02-09T16:36:07.895396Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:1068: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:1068: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:1068: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:1068: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:1068: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "<ipython-input-14-c7e951d11886>:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf_model.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.054339087661662\n"
     ]
    }
   ],
   "source": [
    "# Re-train the model on the full training data\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "# Get cross-validation predictions\n",
    "y_train_pred = cross_val_predict(rf_model, X_train, y_train, cv=5)\n",
    "# Train the best model on the full training data\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "\n",
    "# Predict on the test set\n",
    "mse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(f'RMSE: {np.sqrt(mse)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T12:12:18.128279Z",
     "iopub.status.busy": "2025-02-09T12:12:18.127926Z",
     "iopub.status.idle": "2025-02-09T12:25:32.424248Z",
     "shell.execute_reply": "2025-02-09T12:25:32.423403Z",
     "shell.execute_reply.started": "2025-02-09T12:12:18.128253Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-09 12:12:18,131] A new study created in memory with name: no-name-65833556-b752-4457-acf0-b9dc5b41b96c\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:12:18] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-09 12:12:31,893] Trial 0 finished with value: 0.0026745383435352464 and parameters: {'learning_rate': 0.14732908947642276, 'max_depth': 5, 'subsample': 0.8476089054623736, 'colsample_bytree': 0.7305993735376146, 'reg_alpha': 0.5812000930242557, 'reg_lambda': 3.4948048158713974}. Best is trial 0 with value: 0.0026745383435352464.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:12:31] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-09 12:12:48,053] Trial 1 finished with value: 0.0025499964454778657 and parameters: {'learning_rate': 0.10780166813929862, 'max_depth': 4, 'subsample': 0.592678259316179, 'colsample_bytree': 0.5840135298244427, 'reg_alpha': 0.42294384578032707, 'reg_lambda': 4.169657468633202}. Best is trial 1 with value: 0.0025499964454778657.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:12:48] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-09 12:13:18,123] Trial 2 finished with value: 0.002085070990526914 and parameters: {'learning_rate': 0.05742052036363671, 'max_depth': 11, 'subsample': 0.6492672330715723, 'colsample_bytree': 0.625414608048233, 'reg_alpha': 0.2467039550115384, 'reg_lambda': 3.8146172474605464}. Best is trial 2 with value: 0.002085070990526914.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:13:18] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-09 12:13:33,329] Trial 3 finished with value: 0.002532169336007963 and parameters: {'learning_rate': 0.08639365324811997, 'max_depth': 5, 'subsample': 0.719817722928387, 'colsample_bytree': 0.8083075406691901, 'reg_alpha': 0.6072689714466846, 'reg_lambda': 2.447395976186681}. Best is trial 2 with value: 0.002085070990526914.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:13:33] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-09 12:13:47,030] Trial 4 finished with value: 0.00281897751931609 and parameters: {'learning_rate': 0.09977530629496288, 'max_depth': 6, 'subsample': 0.5449806795473475, 'colsample_bytree': 0.9496325288302888, 'reg_alpha': 0.965294847161422, 'reg_lambda': 1.0212325800523159}. Best is trial 2 with value: 0.002085070990526914.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:13:47] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-09 12:14:01,153] Trial 5 finished with value: 0.002563628668615733 and parameters: {'learning_rate': 0.10009286391519924, 'max_depth': 9, 'subsample': 0.8761081753811166, 'colsample_bytree': 0.9056179530702768, 'reg_alpha': 0.8993637299524635, 'reg_lambda': 2.0152060365375584}. Best is trial 2 with value: 0.002085070990526914.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:14:01] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-09 12:14:25,765] Trial 6 finished with value: 0.0021050476475931645 and parameters: {'learning_rate': 0.17296033073314637, 'max_depth': 8, 'subsample': 0.6322653383350978, 'colsample_bytree': 0.6374767833342141, 'reg_alpha': 0.2092101083072987, 'reg_lambda': 3.579497512992098}. Best is trial 2 with value: 0.002085070990526914.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:14:25] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-09 12:14:49,359] Trial 7 finished with value: 0.002472348520209763 and parameters: {'learning_rate': 0.029958708433982795, 'max_depth': 8, 'subsample': 0.7729639375159632, 'colsample_bytree': 0.7998197947726822, 'reg_alpha': 0.720437377181613, 'reg_lambda': 1.8869340055480794}. Best is trial 2 with value: 0.002085070990526914.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:14:49] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-09 12:15:06,603] Trial 8 finished with value: 0.0022337119823942412 and parameters: {'learning_rate': 0.14666801009836833, 'max_depth': 8, 'subsample': 0.6482003352100443, 'colsample_bytree': 0.8919832428327309, 'reg_alpha': 0.3908099730671307, 'reg_lambda': 2.347202494265082}. Best is trial 2 with value: 0.002085070990526914.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:15:06] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-09 12:15:23,653] Trial 9 finished with value: 0.002465326301683265 and parameters: {'learning_rate': 0.10804731696158243, 'max_depth': 5, 'subsample': 0.5766431538435609, 'colsample_bytree': 0.5793619849801016, 'reg_alpha': 0.4135947561310953, 'reg_lambda': 1.3699355682502619}. Best is trial 2 with value: 0.002085070990526914.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:15:23] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-09 12:18:23,860] Trial 10 finished with value: 0.0015019409003177613 and parameters: {'learning_rate': 0.005874302462010629, 'max_depth': 14, 'subsample': 0.9671985420036247, 'colsample_bytree': 0.504163927700474, 'reg_alpha': 0.0026961225198311456, 'reg_lambda': 4.802038438411944}. Best is trial 10 with value: 0.0015019409003177613.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:18:23] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-09 12:20:54,921] Trial 11 finished with value: 0.001525907410488293 and parameters: {'learning_rate': 0.006612600736428012, 'max_depth': 14, 'subsample': 0.998628671571115, 'colsample_bytree': 0.5200612526003491, 'reg_alpha': 0.011954936549957305, 'reg_lambda': 4.92221030001782}. Best is trial 10 with value: 0.0015019409003177613.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:20:54] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-09 12:22:21,761] Trial 12 finished with value: 0.001567767090159506 and parameters: {'learning_rate': 0.011980272330157901, 'max_depth': 15, 'subsample': 0.9955893884745868, 'colsample_bytree': 0.5041323804588766, 'reg_alpha': 0.03338376927240877, 'reg_lambda': 4.907334703100975}. Best is trial 10 with value: 0.0015019409003177613.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:22:21] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-09 12:25:03,976] Trial 13 finished with value: 0.0015124415491398063 and parameters: {'learning_rate': 0.0066143109064252595, 'max_depth': 15, 'subsample': 0.9946401594379588, 'colsample_bytree': 0.5014461817517148, 'reg_alpha': 0.007553103148637578, 'reg_lambda': 4.993697589526369}. Best is trial 10 with value: 0.0015019409003177613.\n",
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [12:25:04] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-09 12:25:32,419] Trial 14 finished with value: 0.0017661608666695353 and parameters: {'learning_rate': 0.050257662921124796, 'max_depth': 12, 'subsample': 0.9002197754245749, 'colsample_bytree': 0.7033918288947628, 'reg_alpha': 0.15684424153926488, 'reg_lambda': 0.2444379784833255}. Best is trial 10 with value: 0.0015019409003177613.\n"
     ]
    }
   ],
   "source": [
    "best_n_estimators = 1999\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': best_n_estimators,\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.2),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 1.0),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 5.0),\n",
    "    }\n",
    "    \n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "    model = xgb.train(params, dtrain, num_boost_round=params['n_estimators'])\n",
    "    \n",
    "    preds = model.predict(dtest)\n",
    "    return mean_squared_error(y_test, preds, squared=False) # RMSE\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=15)\n",
    "\n",
    "best_params = study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trial 11 finished with value: 0.0013545071142224234 and parameters: {'learning_rate': 0.01861885913259459, 'max_depth': 10, 'subsample': 0.8358619178926193, 'colsample_bytree': 0.8403892834887154, 'reg_alpha': 0.002382874488102673, 'reg_lambda': 0.6066665118899315}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trial 11 finished with value: 0.0016639691136858914 and parameters: {'learning_rate': 0.08846867966096117, 'max_depth': 13, 'subsample': 0.6191093025892407, 'colsample_bytree': 0.6963141610127959, 'reg_alpha': 0.049171806546736925, 'reg_lambda': 2.9803541719046174}. Best is trial 11 with value: 0.0016639691136858914."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trial 10 finished with value: 0.0015019409003177613 and parameters: {'learning_rate': 0.005874302462010629, 'max_depth': 14, 'subsample': 0.9671985420036247, 'colsample_bytree': 0.504163927700474, 'reg_alpha': 0.0026961225198311456, 'reg_lambda': 4.802038438411944}. Best is trial 10 with value: 0.0015019409003177613."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T12:26:39.554791Z",
     "iopub.status.busy": "2025-02-09T12:26:39.554400Z",
     "iopub.status.idle": "2025-02-09T12:28:49.225888Z",
     "shell.execute_reply": "2025-02-09T12:28:49.223936Z",
     "shell.execute_reply.started": "2025-02-09T12:26:39.554760Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_stacking.py:957: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035268 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26014\n",
      "[LightGBM] [Info] Number of data points in the train set: 45360, number of used features: 104\n",
      "[LightGBM] [Info] Start training from score 0.685492\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024943 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26014\n",
      "[LightGBM] [Info] Number of data points in the train set: 36288, number of used features: 104\n",
      "[LightGBM] [Info] Start training from score 0.685640\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024989 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26014\n",
      "[LightGBM] [Info] Number of data points in the train set: 36288, number of used features: 104\n",
      "[LightGBM] [Info] Start training from score 0.686254\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024518 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26014\n",
      "[LightGBM] [Info] Number of data points in the train set: 36288, number of used features: 104\n",
      "[LightGBM] [Info] Start training from score 0.685257\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26014\n",
      "[LightGBM] [Info] Number of data points in the train set: 36288, number of used features: 104\n",
      "[LightGBM] [Info] Start training from score 0.685018\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024722 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26014\n",
      "[LightGBM] [Info] Number of data points in the train set: 36288, number of used features: 104\n",
      "[LightGBM] [Info] Start training from score 0.685293\n",
      "RMSE: 0.053853692324096834\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "\n",
    "# Define parameters for XGBoost\n",
    "params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'n_estimators': 1999,\n",
    "    'learning_rate': 0.08846867966096117,   # Smaller learning rate improves generalization\n",
    "    'max_depth': 13,          # Higher depth captures more interactions\n",
    "    'subsample':  0.6191093025892407,        # Prevents overfitting\n",
    "    'colsample_bytree': 0.6963141610127959, # Feature selection\n",
    "    'reg_alpha': 0.049171806546736925,        # L1 regularization\n",
    "    'reg_lambda': 2.9803541719046174,       # L2 regularization\n",
    "    'n_jobs': -1\n",
    "}\n",
    "num_round = 100\n",
    "\n",
    "# Train the model\n",
    "\n",
    "# bst = xgb.train(params, dtrain, num_round)\n",
    "xgb_model = XGBRegressor(**best_params)\n",
    "lgb_model = LGBMRegressor(n_estimators=500, learning_rate=0.05)\n",
    "cat_model = CatBoostRegressor(n_estimators=500, learning_rate=0.05, verbose=0)\n",
    "\n",
    "stack_model = StackingRegressor(estimators=[\n",
    "    ('xgb', xgb_model),\n",
    "], final_estimator=XGBRegressor(n_estimators=100))\n",
    "\n",
    "stack_model.fit(X_train, y_train)\n",
    "\n",
    "# dtest = xgb.DMatrix(X_test)\n",
    "# predictions = bst.predict(dtest)\n",
    "predictions = stack_model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, predictions, squared=False)\n",
    "print(f'RMSE: {np.sqrt(mse)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11034314,
     "sourceId": 92582,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30886,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
